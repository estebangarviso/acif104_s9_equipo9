{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f0a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Imports\n",
    "# ===========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Directorios\n",
    "EXPORTS_DIR = Path('../exports')\n",
    "MODELS = ['randomforest', 'xgboost', 'stacking', 'mlp', 'lstm']\n",
    "COLORS = {'randomforest': '#2ecc71', 'xgboost': '#3498db', 'stacking': '#9b59b6', \n",
    "          'mlp': '#e74c3c', 'lstm': '#f39c12'}\n",
    "\n",
    "print(\"‚úÖ Imports completados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eac7c50",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Comparaci√≥n de M√©tricas\n",
    "\n",
    "Cargar todas las predicciones y calcular m√©tricas comparativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d8c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cargar predicciones VAL y TEST\n",
    "# ===========================\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "metrics_comparison = []\n",
    "\n",
    "for model_name in MODELS:\n",
    "    for split in ['val', 'test']:\n",
    "        pred_file = EXPORTS_DIR / f'predictions_{model_name}_{split}.csv'\n",
    "        \n",
    "        if not pred_file.exists():\n",
    "            print(f\"‚ö†Ô∏è {pred_file.name} no encontrado\")\n",
    "            continue\n",
    "        \n",
    "        df = pd.read_csv(pred_file)\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(df['y_true'], df['y_pred']))\n",
    "        mae = mean_absolute_error(df['y_true'], df['y_pred'])\n",
    "        r2 = r2_score(df['y_true'], df['y_pred'])\n",
    "        \n",
    "        metrics_comparison.append({\n",
    "            'model': model_name,\n",
    "            'split': split,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'r2': r2,\n",
    "            'n_samples': len(df)\n",
    "        })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_comparison)\n",
    "\n",
    "# Tabla comparativa\n",
    "print(\"\\nüìä TABLA COMPARATIVA DE M√âTRICAS\\n\")\n",
    "pivot_table = metrics_df.pivot_table(\n",
    "    index='model', \n",
    "    columns='split', \n",
    "    values=['rmse', 'mae', 'r2']\n",
    ").round(4)\n",
    "print(pivot_table)\n",
    "\n",
    "# Mejor modelo por RMSE en val\n",
    "best_val = metrics_df[metrics_df['split'] == 'val'].sort_values('rmse').iloc[0]\n",
    "print(f\"\\nüèÜ Mejor modelo (VAL): {best_val['model'].upper()} - RMSE: {best_val['rmse']:.4f}\")\n",
    "\n",
    "# Mejor modelo por RMSE en test\n",
    "best_test = metrics_df[metrics_df['split'] == 'test'].sort_values('rmse').iloc[0]\n",
    "print(f\"üèÜ Mejor modelo (TEST): {best_test['model'].upper()} - RMSE: {best_test['rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97b2470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Visualizaci√≥n: Comparaci√≥n de RMSE\n",
    "# ===========================\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# RMSE por modelo y split\n",
    "rmse_pivot = metrics_df.pivot(index='model', columns='split', values='rmse')\n",
    "rmse_pivot.plot(kind='bar', ax=axes[0], color=['#3498db', '#e74c3c'], alpha=0.8)\n",
    "axes[0].set_title('RMSE por Modelo y Split', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Modelo')\n",
    "axes[0].set_ylabel('RMSE')\n",
    "axes[0].legend(title='Split', labels=['Val', 'Test'])\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# MAE por modelo y split\n",
    "mae_pivot = metrics_df.pivot(index='model', columns='split', values='mae')\n",
    "mae_pivot.plot(kind='bar', ax=axes[1], color=['#2ecc71', '#f39c12'], alpha=0.8)\n",
    "axes[1].set_title('MAE por Modelo y Split', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Modelo')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].legend(title='Split', labels=['Val', 'Test'])\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# R¬≤ por modelo y split\n",
    "r2_pivot = metrics_df.pivot(index='model', columns='split', values='r2')\n",
    "r2_pivot.plot(kind='bar', ax=axes[2], color=['#9b59b6', '#34495e'], alpha=0.8)\n",
    "axes[2].set_title('R¬≤ por Modelo y Split', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Modelo')\n",
    "axes[2].set_ylabel('R¬≤')\n",
    "axes[2].legend(title='Split', labels=['Val', 'Test'])\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(EXPORTS_DIR / 'comparison_metrics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Gr√°fico guardado: comparison_metrics.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4e221d",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Distribuci√≥n de Errores\n",
    "\n",
    "Analizar distribuciones de residuales para cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1541796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Distribuci√≥n de residuales (VAL)\n",
    "# ===========================\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, model_name in enumerate(MODELS):\n",
    "    pred_file = EXPORTS_DIR / f'predictions_{model_name}_val.csv'\n",
    "    \n",
    "    if not pred_file.exists():\n",
    "        continue\n",
    "    \n",
    "    df = pd.read_csv(pred_file)\n",
    "    \n",
    "    # Histograma\n",
    "    axes[idx].hist(df['residual'], bins=50, color=COLORS[model_name], alpha=0.7, edgecolor='black')\n",
    "    axes[idx].axvline(0, color='red', linestyle='--', linewidth=2, label='Error=0')\n",
    "    axes[idx].set_title(f'{model_name.upper()} - Distribuci√≥n de Residuales (VAL)', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Residual (y_true - y_pred)')\n",
    "    axes[idx].set_ylabel('Frecuencia')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "    \n",
    "    # Estad√≠sticas\n",
    "    mean_res = df['residual'].mean()\n",
    "    std_res = df['residual'].std()\n",
    "    axes[idx].text(0.95, 0.95, f'Œº={mean_res:.2f}\\nœÉ={std_res:.2f}', \n",
    "                  transform=axes[idx].transAxes, \n",
    "                  verticalalignment='top', horizontalalignment='right',\n",
    "                  bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# Ocultar subplot extra\n",
    "axes[5].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(EXPORTS_DIR / 'comparison_residuals_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Gr√°fico guardado: comparison_residuals_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7fd7cf",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Residuales por Segmento\n",
    "\n",
    "Analizar c√≥mo se comportan los errores en diferentes clusters de tiendas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c127c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Boxplots de residuales por cluster\n",
    "# ===========================\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, model_name in enumerate(MODELS):\n",
    "    pred_file = EXPORTS_DIR / f'predictions_{model_name}_val.csv'\n",
    "    \n",
    "    if not pred_file.exists():\n",
    "        continue\n",
    "    \n",
    "    df = pd.read_csv(pred_file)\n",
    "    \n",
    "    # Boxplot por cluster\n",
    "    df.boxplot(column='residual', by='shop_cluster', ax=axes[idx], \n",
    "               patch_artist=True, grid=False)\n",
    "    \n",
    "    # Personalizar\n",
    "    axes[idx].set_title(f'{model_name.upper()} - Residuales por Cluster (VAL)', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Shop Cluster')\n",
    "    axes[idx].set_ylabel('Residual')\n",
    "    axes[idx].axhline(0, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    plt.sca(axes[idx])\n",
    "    plt.xticks(rotation=0)\n",
    "\n",
    "# Ocultar subplot extra\n",
    "axes[5].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(EXPORTS_DIR / 'comparison_residuals_by_cluster.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Gr√°fico guardado: comparison_residuals_by_cluster.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cd8401",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Comparaci√≥n SHAP (RandomForest vs XGBoost)\n",
    "\n",
    "Comparar la importancia de features entre los dos modelos tree-based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e626a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Comparaci√≥n SHAP (Top 10 features)\n",
    "# ===========================\n",
    "shap_rf = pd.read_csv(EXPORTS_DIR / 'shap_summary_randomforest_val.csv')\n",
    "shap_xgb = pd.read_csv(EXPORTS_DIR / 'shap_summary_xgboost_val.csv')\n",
    "\n",
    "# Top 10 features de cada modelo\n",
    "top_rf = shap_rf.nsmallest(10, 'rank')[['feature', 'mean_abs_shap_value']].copy()\n",
    "top_rf['model'] = 'RandomForest'\n",
    "\n",
    "top_xgb = shap_xgb.nsmallest(10, 'rank')[['feature', 'mean_abs_shap_value']].copy()\n",
    "top_xgb['model'] = 'XGBoost'\n",
    "\n",
    "# Combinar\n",
    "top_features = pd.concat([top_rf, top_xgb])\n",
    "\n",
    "# Visualizaci√≥n\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Barplot agrupado\n",
    "x = np.arange(10)\n",
    "width = 0.35\n",
    "\n",
    "rf_values = top_rf['mean_abs_shap_value'].values\n",
    "xgb_values = top_xgb['mean_abs_shap_value'].values\n",
    "rf_features = top_rf['feature'].values\n",
    "\n",
    "ax.barh(x - width/2, rf_values, width, label='RandomForest', color=COLORS['randomforest'], alpha=0.8)\n",
    "ax.barh(x + width/2, xgb_values, width, label='XGBoost', color=COLORS['xgboost'], alpha=0.8)\n",
    "\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(rf_features)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Mean |SHAP Value|', fontsize=12)\n",
    "ax.set_title('Top 10 Features - Comparaci√≥n SHAP (RF vs XGB)', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(EXPORTS_DIR / 'comparison_shap_rf_vs_xgb.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Gr√°fico guardado: comparison_shap_rf_vs_xgb.png\")\n",
    "\n",
    "# Consistencia de features\n",
    "common_features = set(top_rf['feature']) & set(top_xgb['feature'])\n",
    "print(f\"\\nüîç Features comunes en Top 10: {len(common_features)}/10\")\n",
    "print(f\"   {', '.join(sorted(common_features))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076af151",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Curvas de Aprendizaje (DL Models)\n",
    "\n",
    "Comparar la convergencia de MLP vs LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d7fd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Curvas de aprendizaje MLP vs LSTM\n",
    "# ===========================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "for idx, model_name in enumerate(['mlp', 'lstm']):\n",
    "    curve_file = EXPORTS_DIR / f'learning_curves_{model_name}.csv'\n",
    "    \n",
    "    if not curve_file.exists():\n",
    "        axes[idx].text(0.5, 0.5, f'{model_name.upper()} learning curves no disponibles', \n",
    "                      ha='center', va='center', transform=axes[idx].transAxes)\n",
    "        continue\n",
    "    \n",
    "    df = pd.read_csv(curve_file)\n",
    "    \n",
    "    # Plot train y val loss\n",
    "    axes[idx].plot(df['epoch'], df['train_loss'], label='Train Loss', \n",
    "                  color=COLORS[model_name], linewidth=2)\n",
    "    \n",
    "    if 'val_loss' in df.columns and not df['val_loss'].isna().all():\n",
    "        axes[idx].plot(df['epoch'], df['val_loss'], label='Val Loss', \n",
    "                      color='red', linewidth=2, linestyle='--')\n",
    "    \n",
    "    axes[idx].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[idx].set_ylabel('Loss (MSE)', fontsize=12)\n",
    "    axes[idx].set_title(f'{model_name.upper()} - Curva de Aprendizaje', \n",
    "                       fontsize=14, fontweight='bold')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "    \n",
    "    # Marcar mejor epoch (menor val_loss)\n",
    "    if 'val_loss' in df.columns and not df['val_loss'].isna().all():\n",
    "        best_epoch = df['val_loss'].idxmin() + 1\n",
    "        best_loss = df.loc[best_epoch-1, 'val_loss']\n",
    "        axes[idx].scatter(best_epoch, best_loss, color='red', s=100, zorder=5, marker='*')\n",
    "        axes[idx].annotate(f'Best: Epoch {best_epoch}', \n",
    "                          xy=(best_epoch, best_loss), \n",
    "                          xytext=(10, 10), textcoords='offset points',\n",
    "                          bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5),\n",
    "                          arrowprops=dict(arrowstyle='->', color='black'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(EXPORTS_DIR / 'comparison_learning_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Gr√°fico guardado: comparison_learning_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b9fa90",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Generalizaci√≥n: Val vs Test\n",
    "\n",
    "Analizar la diferencia de RMSE entre validaci√≥n y test para detectar overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d0f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# An√°lisis de generalizaci√≥n\n",
    "# ===========================\n",
    "generalization = []\n",
    "\n",
    "for model_name in MODELS:\n",
    "    val_metrics = metrics_df[(metrics_df['model'] == model_name) & (metrics_df['split'] == 'val')]\n",
    "    test_metrics = metrics_df[(metrics_df['model'] == model_name) & (metrics_df['split'] == 'test')]\n",
    "    \n",
    "    if len(val_metrics) == 0 or len(test_metrics) == 0:\n",
    "        continue\n",
    "    \n",
    "    val_rmse = val_metrics['rmse'].values[0]\n",
    "    test_rmse = test_metrics['rmse'].values[0]\n",
    "    diff = test_rmse - val_rmse\n",
    "    pct_diff = (diff / val_rmse) * 100\n",
    "    \n",
    "    generalization.append({\n",
    "        'model': model_name,\n",
    "        'val_rmse': val_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'diff': diff,\n",
    "        'pct_diff': pct_diff\n",
    "    })\n",
    "\n",
    "gen_df = pd.DataFrame(generalization)\n",
    "\n",
    "# Tabla\n",
    "print(\"\\nüìä AN√ÅLISIS DE GENERALIZACI√ìN (Val vs Test)\\n\")\n",
    "print(gen_df.to_string(index=False))\n",
    "\n",
    "# Visualizaci√≥n\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(gen_df))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, gen_df['val_rmse'], width, label='Val RMSE', \n",
    "       color='#3498db', alpha=0.8)\n",
    "ax.bar(x + width/2, gen_df['test_rmse'], width, label='Test RMSE', \n",
    "       color='#e74c3c', alpha=0.8)\n",
    "\n",
    "# Marcar diferencias\n",
    "for i, row in gen_df.iterrows():\n",
    "    if row['diff'] > 0:\n",
    "        color = 'red'\n",
    "        label = f'+{row[\"pct_diff\"]:.1f}%'\n",
    "    else:\n",
    "        color = 'green'\n",
    "        label = f'{row[\"pct_diff\"]:.1f}%'\n",
    "    \n",
    "    ax.text(i, max(row['val_rmse'], row['test_rmse']) + 0.05, label, \n",
    "           ha='center', color=color, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Modelo', fontsize=12)\n",
    "ax.set_ylabel('RMSE', fontsize=12)\n",
    "ax.set_title('Generalizaci√≥n: Val vs Test RMSE', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([m.upper() for m in gen_df['model']], rotation=45)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(EXPORTS_DIR / 'comparison_generalization.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Gr√°fico guardado: comparison_generalization.png\")\n",
    "\n",
    "# Modelo m√°s estable\n",
    "most_stable = gen_df.loc[gen_df['pct_diff'].abs().idxmin()]\n",
    "print(f\"\\nüéØ Modelo m√°s estable: {most_stable['model'].upper()} ({most_stable['pct_diff']:.2f}% diff)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172fb427",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Scatter Plots: Predicciones vs Real\n",
    "\n",
    "Visualizar la correlaci√≥n entre predicciones y valores reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f806bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Scatter plots: y_pred vs y_true\n",
    "# ===========================\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, model_name in enumerate(MODELS):\n",
    "    pred_file = EXPORTS_DIR / f'predictions_{model_name}_val.csv'\n",
    "    \n",
    "    if not pred_file.exists():\n",
    "        continue\n",
    "    \n",
    "    df = pd.read_csv(pred_file)\n",
    "    \n",
    "    # Sample para performance (max 5000 puntos)\n",
    "    if len(df) > 5000:\n",
    "        df_sample = df.sample(5000, random_state=42)\n",
    "    else:\n",
    "        df_sample = df\n",
    "    \n",
    "    # Scatter\n",
    "    axes[idx].scatter(df_sample['y_true'], df_sample['y_pred'], \n",
    "                     alpha=0.3, s=10, color=COLORS[model_name])\n",
    "    \n",
    "    # L√≠nea perfecta\n",
    "    max_val = max(df_sample['y_true'].max(), df_sample['y_pred'].max())\n",
    "    axes[idx].plot([0, max_val], [0, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "    \n",
    "    axes[idx].set_xlabel('y_true', fontsize=11)\n",
    "    axes[idx].set_ylabel('y_pred', fontsize=11)\n",
    "    axes[idx].set_title(f'{model_name.upper()} - Predicciones vs Real (VAL)', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "    \n",
    "    # R¬≤ en el gr√°fico\n",
    "    r2 = r2_score(df['y_true'], df['y_pred'])\n",
    "    axes[idx].text(0.05, 0.95, f'R¬≤ = {r2:.4f}', \n",
    "                  transform=axes[idx].transAxes, \n",
    "                  verticalalignment='top',\n",
    "                  bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
    "\n",
    "# Ocultar subplot extra\n",
    "axes[5].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(EXPORTS_DIR / 'comparison_scatter_pred_vs_true.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Gr√°fico guardado: comparison_scatter_pred_vs_true.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245fee0c",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Resumen Final\n",
    "\n",
    "Generar un reporte consolidado de todos los an√°lisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4692ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Resumen consolidado\n",
    "# ===========================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ RESUMEN CONSOLIDADO - AN√ÅLISIS COMPARATIVO\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "print(\"üìä 1. MEJOR MODELO POR M√âTRICA (VALIDACI√ìN)\")\n",
    "val_metrics = metrics_df[metrics_df['split'] == 'val']\n",
    "print(f\"   ‚Ä¢ RMSE: {val_metrics.loc[val_metrics['rmse'].idxmin(), 'model'].upper()} ({val_metrics['rmse'].min():.4f})\")\n",
    "print(f\"   ‚Ä¢ MAE:  {val_metrics.loc[val_metrics['mae'].idxmin(), 'model'].upper()} ({val_metrics['mae'].min():.4f})\")\n",
    "print(f\"   ‚Ä¢ R¬≤:   {val_metrics.loc[val_metrics['r2'].idxmax(), 'model'].upper()} ({val_metrics['r2'].max():.4f})\")\n",
    "\n",
    "print(\"\\nüìä 2. MEJOR MODELO POR M√âTRICA (TEST)\")\n",
    "test_metrics = metrics_df[metrics_df['split'] == 'test']\n",
    "print(f\"   ‚Ä¢ RMSE: {test_metrics.loc[test_metrics['rmse'].idxmin(), 'model'].upper()} ({test_metrics['rmse'].min():.4f})\")\n",
    "print(f\"   ‚Ä¢ MAE:  {test_metrics.loc[test_metrics['mae'].idxmin(), 'model'].upper()} ({test_metrics['mae'].min():.4f})\")\n",
    "print(f\"   ‚Ä¢ R¬≤:   {test_metrics.loc[test_metrics['r2'].idxmax(), 'model'].upper()} ({test_metrics['r2'].max():.4f})\")\n",
    "\n",
    "print(f\"\\nüéØ 3. MODELO M√ÅS ESTABLE (Val‚ÜíTest)\")\n",
    "print(f\"   {most_stable['model'].upper()} con {most_stable['pct_diff']:.2f}% de diferencia\")\n",
    "\n",
    "print(f\"\\nüîç 4. CONSISTENCIA DE FEATURES (SHAP)\")\n",
    "print(f\"   {len(common_features)}/10 features comunes en Top 10 (RF vs XGB)\")\n",
    "\n",
    "print(\"\\nüìà 5. GR√ÅFICOS GENERADOS\")\n",
    "generated_plots = [\n",
    "    'comparison_metrics.png',\n",
    "    'comparison_residuals_distribution.png',\n",
    "    'comparison_residuals_by_cluster.png',\n",
    "    'comparison_shap_rf_vs_xgb.png',\n",
    "    'comparison_learning_curves.png',\n",
    "    'comparison_generalization.png',\n",
    "    'comparison_scatter_pred_vs_true.png'\n",
    "]\n",
    "for plot in generated_plots:\n",
    "    if (EXPORTS_DIR / plot).exists():\n",
    "        print(f\"   ‚úÖ {plot}\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è {plot} (no generado)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ AN√ÅLISIS COMPARATIVO COMPLETADO\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
