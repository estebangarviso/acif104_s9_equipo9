# ğŸ“ˆ PredicciÃ³n de Demanda en E-commerce - Equipo 9 (ACIF104)

Este repositorio contiene el proyecto final para la asignatura **Aprendizaje de MÃ¡quinas (ACIF104)** de la Universidad AndrÃ©s Bello. El objetivo es desarrollar un sistema robusto de predicciÃ³n de demanda para retail utilizando una arquitectura de **Ensemble Learning (Stacking)**, enriquecida con **Clustering Particional** y desplegada mediante una aplicaciÃ³n web interactiva con **Streamlit**.

## ğŸ‘¥ Integrantes del Equipo

* **Esteban Garviso**
* **Felipe Ortega**

---

## ğŸ“‚ Estructura del Proyecto

El repositorio sigue una arquitectura modular que separa claramente la lÃ³gica de negocio (Backend) de la interfaz de usuario (Frontend), cumpliendo con los estÃ¡ndares de ingenierÃ­a de software.

```text
acif104_s9_equipo9/
â”‚
â”œâ”€â”€ README.md               # DocumentaciÃ³n principal y manual de ejecuciÃ³n.
â”œâ”€â”€ Pipfile                 # DefiniciÃ³n de dependencias y scripts del entorno.
â”œâ”€â”€ Pipfile.lock            # Ãrbol de dependencias exacto (Hash) para reproducibilidad.
â”œâ”€â”€ pyproject.toml          # ConfiguraciÃ³n centralizada de Linters (Black, Isort, Mypy).
â”‚
â”œâ”€â”€ data/                   # Almacenamiento local de datos.
â”‚   â”œâ”€â”€ raw/                # Los datos se descargan aquÃ­ automÃ¡ticamente vÃ­a KaggleHub.
â”‚   â””â”€â”€ processed/          # Datos transformados listos para entrenamiento.
â”‚
â”œâ”€â”€ notebooks/              # AnÃ¡lisis exploratorio y prototipado rÃ¡pido.
â”‚   â”œâ”€â”€ 01_EDA_Clustering.ipynb      # AnÃ¡lisis de outliers, K-Means y patrones temporales.
â”‚   â””â”€â”€ 02_Modelado_Ensemble.ipynb   # Experimentos con Stacking y Deep Learning.
â”‚
â”œâ”€â”€ src/                    # Backend: LÃ³gica de Negocio y Modelado.
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_processing.py  # Pipeline de limpieza, clustering y feature engineering.
â”‚   â”œâ”€â”€ train.py            # Script de entrenamiento, validaciÃ³n y serializaciÃ³n.
â”‚   â””â”€â”€ inference.py        # Motor de inferencia para la aplicaciÃ³n.
â”‚
â”œâ”€â”€ app/                    # Frontend: Interfaz de Usuario.
â”‚   â””â”€â”€ app.py              # AplicaciÃ³n web interactiva (Streamlit).
â”‚
â””â”€â”€ models/                 # Artefactos serializados (Modelos entrenados).
    â”œâ”€â”€ stacking_model.pkl  # Modelo final de ensamble.
    â”œâ”€â”€ features.pkl        # Metadatos de columnas.
    â””â”€â”€ xgb_simple_shap.pkl # Modelo proxy para explicabilidad SHAP.
````

## ğŸ› ï¸ InstalaciÃ³n y ConfiguraciÃ³n

Este proyecto utiliza **Pipenv** para asegurar un entorno determinista y **KaggleHub** para la gestiÃ³n automÃ¡tica del dataset.

### 1\. Prerrequisitos

* **Python:** VersiÃ³n 3.10 (Requerido).
* **Gestor de Paquetes:** `pipenv` instalado globalmente.

```bash
pip install pipenv
```

### 2\. Clonar el Repositorio

```bash
git clone https://github.com/estebangarviso/acif104_s9_equipo9.git
cd acif104_s9_equipo9
```

### 3\. Instalar Dependencias

Ejecuta el siguiente comando para crear el entorno virtual e instalar las librerÃ­as exactas definidas en el `Pipfile.lock`:

```bash
pipenv install --ignore-pipfile
```

*(Para desarrollo, incluye las herramientas de calidad de cÃ³digo: `pipenv install --dev`)*

## ğŸš€ Manual de EjecuciÃ³n

Hemos configurado **scripts automatizados** en Pipenv para facilitar el ciclo de vida del desarrollo. No es necesario activar el shell manualmente si usas `pipenv run`.

### A. Entrenamiento del Modelo (Backend)

Este comando descarga automÃ¡ticamente el dataset desde Kaggle (si no existe), aplica el preprocesamiento (Clustering + Lags), entrena el Ensemble y guarda los modelos en la carpeta `models/`.

```bash
pipenv run train
```

*Salida esperada:* Archivos `stacking_model.pkl` y `features.pkl` generados en `models/`.

### B. Iniciar la AplicaciÃ³n Web (Frontend)

Despliega la interfaz grÃ¡fica para interactuar con el modelo y visualizar la explicabilidad (SHAP).

```bash
pipenv run start
```

*La aplicaciÃ³n se abrirÃ¡ automÃ¡ticamente en tu navegador (<http://localhost:8501>).*

## ğŸ›¡ï¸ Calidad de CÃ³digo (QA)

Para garantizar la mantenibilidad y robustez del cÃ³digo, utilizamos un set estricto de herramientas de anÃ¡lisis estÃ¡tico. Puedes ejecutar la suite completa con un solo comando:

```bash
pipenv run check-all
```

O ejecutar herramientas individuales:

* **Formato:** `pipenv run format` (Aplica **Black** e **Isort**).
* **Linting:** `pipenv run lint` (Analiza el cÃ³digo con **Pylint**).
* **Tipado:** `pipenv run type-check` (Valida tipos estÃ¡ticos con **Mypy**).

## ğŸ§  DescripciÃ³n TÃ©cnica del Sistema

### 1\. MetodologÃ­a

El proyecto sigue la metodologÃ­a **CRISP-DM**, abarcando desde el entendimiento del negocio hasta el despliegue del prototipo.

### 2\. Arquitectura del Modelo (Stacking)

Para maximizar la capacidad predictiva, implementamos un **Ensemble HeterogÃ©neo**:

* **Nivel Base:**
  * *Random Forest Regressor:* Captura relaciones no lineales y reduce varianza.
  * *XGBoost:* Optimiza el sesgo mediante Gradient Boosting.
* **Meta-Modelo:**
  * *RegresiÃ³n Lineal:* Combina las predicciones base para generar la estimaciÃ³n final.

### 3\. IngenierÃ­a de CaracterÃ­sticas Avanzada

* **Clustering Particional (K-Means):** SegmentaciÃ³n de tiendas basada en volumen de ventas histÃ³rico para agrupar comportamientos similares.
* **Lags Temporales:** Variables de rezago (t-1, t-2, t-3) para capturar la tendencia secuencial.
* **Balanceo de Datos:** TransformaciÃ³n LogarÃ­tmica (`log1p`) sobre la variable objetivo para normalizar la distribuciÃ³n de ventas.

### 4\. Explicabilidad

Se integra **SHAP (SHapley Additive exPlanations)** en el Frontend para proporcionar transparencia algorÃ­tmica, permitiendo al usuario entender quÃ© variables (precio, categorÃ­a, mes) influyen positiva o negativamente en cada predicciÃ³n.

---

## Universidad AndrÃ©s Bello - 2025
