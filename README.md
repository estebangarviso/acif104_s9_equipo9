# PredicciÃ³n de Demanda en E-commerce - Equipo 9 (ACIF104)

Este repositorio contiene el proyecto final para la asignatura **Aprendizaje de MÃ¡quinas (ACIF104)** de la Universidad AndrÃ©s Bello. El objetivo es desarrollar un sistema robusto de predicciÃ³n de demanda para retail utilizando:

- ğŸ§  **Machine Learning Avanzado**: Ensemble Stacking (Random Forest + XGBoost + meta-estimador) + Deep Learning (MLP + LSTM-DNN)
- ğŸ“Š **IngenierÃ­a de Features Avanzada**: 
  - Clustering K-Means para segmentaciÃ³n de tiendas
  - **24+ features engineered**: Momentum (deltas, aceleraciÃ³n), Sensibilidad al Precio (elasticidad, ingresos), Desviaciones (z-scores, volatilidad)
  - **Exactamente 2 ventanas rolling parametrizables** (default: 3 y 6 meses)
  - Balanceo con SMOTE opcional
- ğŸŒ **Arquitectura Desacoplada**: Backend REST API (FastAPI) + Frontend (Streamlit) con comunicaciÃ³n HTTP
- ğŸ”„ **MLOps Best Practices**: ValidaciÃ³n temporal, sincronizaciÃ³n automÃ¡tica de dependencias, versionado de modelos

## Integrantes del Equipo

* **Esteban Garviso**
* **Felipe Ortega**

## Estructura del Proyecto

El proyecto sigue una arquitectura modular que desacopla la lÃ³gica de negocio (Backend REST API) de la capa de presentaciÃ³n (Frontend Streamlit), facilitando la mantenibilidad y escalabilidad:

```text
acif104_s9_equipo9/
â”‚
â”œâ”€â”€ README.md               # DocumentaciÃ³n completa del proyecto
â”œâ”€â”€ Pipfile                 # GestiÃ³n de dependencias con Pipenv
â”œâ”€â”€ Pipfile.lock            # Ãrbol de dependencias exacto (reproducibilidad)
â”œâ”€â”€ requirements.txt        # Dependencias (generado automÃ¡ticamente)
â”œâ”€â”€ requirements-dev.txt    # Dependencias de desarrollo (generado automÃ¡ticamente)
â”œâ”€â”€ Makefile                # Comandos de automatizaciÃ³n (install, train, api, start)
â”œâ”€â”€ pyproject.toml          # ConfiguraciÃ³n de QA (Black, Isort, Mypy)
â”‚
â”œâ”€â”€ .githooks/              # Git hooks personalizados
â”‚   â””â”€â”€ pre-commit          # Auto-sincronizaciÃ³n de requirements.txt al commitear
â”‚
â”œâ”€â”€ data/                   # Datasets con sistema de respaldo automÃ¡tico
â”‚   â”œâ”€â”€ .gitkeep            # Los datos se descargan automÃ¡ticamente vÃ­a KaggleHub
â”‚   â””â”€â”€ [*.csv]             # Respaldo local: sales_train, items, shops, item_categories
â”‚
â”œâ”€â”€ models/                 # Modelos entrenados y metadatos
â”‚   â”œâ”€â”€ stacking_model.pkl  # Ensemble Stacking (Random Forest + XGBoost)
â”‚   â”œâ”€â”€ mlp_model.keras     # Red Neuronal MLP (3 capas densas)
â”‚   â”œâ”€â”€ lstm_model.keras    # Red Neuronal LSTM-DNN simplificada
â”‚   â”œâ”€â”€ scaler.pkl          # StandardScaler para normalizaciÃ³n
â”‚   â””â”€â”€ metrics.json        # MÃ©tricas comparativas (RMSE, MAE, RÂ²)
â”‚
â”œâ”€â”€ notebooks/              # Prototipado y anÃ¡lisis exploratorio
â”‚   â”œâ”€â”€ 01_EDA_Clustering.ipynb      # K-Means, Outliers y patrones temporales
â”‚   â””â”€â”€ 02_Modelado_Ensemble.ipynb   # Experimentos con Stacking y Deep Learning
â”‚
â”œâ”€â”€ src/                    # Backend: LÃ³gica de Negocio y Modelado
â”‚   â”œâ”€â”€ __init__.py         # InicializaciÃ³n del paquete
â”‚   â”œâ”€â”€ data_processing.py  # Pipeline ETL: SMOTE, Rolling Windows, TimeSeriesSplit
â”‚   â”œâ”€â”€ train.py            # Entrenamiento de 5 modelos (RF, XGB, MLP, LSTM, Stacking)
â”‚   â”œâ”€â”€ inference.py        # Motor de inferencia con sistema de respaldo
â”‚   â””â”€â”€ api.py              # FastAPI REST API (5 endpoints con Pydantic)
â”‚
â”œâ”€â”€ app/                    # Frontend: Interfaz de Usuario con Streamlit
â”‚   â”œâ”€â”€ README.md           # DocumentaciÃ³n de arquitectura modular
â”‚   â”œâ”€â”€ app.py              # Punto de entrada principal
â”‚   â”œâ”€â”€ config.py           # Configuraciones centralizadas
â”‚   â”œâ”€â”€ state_manager.py    # GestiÃ³n de estado (Singleton)
â”‚   â”‚
â”‚   â”œâ”€â”€ services/           # LÃ³gica de negocio
â”‚   â”‚   â”œâ”€â”€ pricing_service.py       # Precios dinÃ¡micos por categorÃ­a
â”‚   â”‚   â”œâ”€â”€ prediction_service.py    # Cliente HTTP para API REST
â”‚   â”‚   â””â”€â”€ trend_analyzer.py        # AnÃ¡lisis de tendencias
â”‚   â”‚
â”‚   â”œâ”€â”€ components/         # Componentes de visualizaciÃ³n
â”‚   â”‚   â”œâ”€â”€ chart_builder.py         # GrÃ¡ficos Plotly reutilizables
â”‚   â”‚   â”œâ”€â”€ shap_renderer.py         # Renderizado SHAP (dark/light theme)
â”‚   â”‚   â””â”€â”€ dataframe_builder.py     # ConstrucciÃ³n de DataFrames
â”‚   â”‚
â”‚   â”œâ”€â”€ ui_components/      # Componentes UI
â”‚   â”‚   â”œâ”€â”€ header.py       # Encabezado con branding
â”‚   â”‚   â””â”€â”€ sidebar.py      # Formulario de predicciÃ³n
â”‚   â”‚
â”‚   â””â”€â”€ views/              # Vistas de navegaciÃ³n
â”‚       â”œâ”€â”€ prediction_view.py       # Vista principal de predicciÃ³n
â”‚       â”œâ”€â”€ monitoring_view.py       # Dashboard de monitoreo
â”‚       â””â”€â”€ about_view.py            # InformaciÃ³n del proyecto
```
â”‚   â”‚
â”‚   â”œâ”€â”€ views/              # Vistas principales
â”‚   â”‚   â”œâ”€â”€ prediction_view.py       # AnÃ¡lisis predictivo con KPIs y SHAP
â”‚   â”‚   â”œâ”€â”€ monitoring_view.py       # Salud del modelo + Mantenimiento
â”‚   â”‚   â””â”€â”€ architecture_view.py     # DocumentaciÃ³n tÃ©cnica
â”‚   â”‚
â”‚   â””â”€â”€ ui_components/      # Componentes de UI
â”‚       â”œâ”€â”€ sidebar.py               # Controles laterales y formularios
â”‚       â””â”€â”€ header.py                # Encabezado de la aplicaciÃ³n
â”‚
â””â”€â”€ models/                 # Artefactos serializados (Persistencia)
    â”œâ”€â”€ stacking_model.pkl  # Modelo final de ensamble (RF + XGBoost)
    â”œâ”€â”€ features.pkl        # Metadatos de columnas
    â”œâ”€â”€ xgb_simple_shap.pkl # Modelo proxy para explicabilidad
    â””â”€â”€ category_prices.pkl # Precios promedio por categorÃ­a
```

## Inicio RÃ¡pido

```bash
# 1. Clonar repositorio
git clone https://github.com/estebangarviso/acif104_s9_equipo9.git
cd acif104_s9_equipo9

# 2. Instalar dependencias
pipenv install --ignore-pipfile

# 3. Iniciar Backend (Terminal 1)
pipenv run api

# 4. Iniciar Frontend (Terminal 2)
pipenv run start
```

ğŸ“– **DocumentaciÃ³n completa:** Ver [docs/INSTALLATION.md](docs/INSTALLATION.md)

## CaracterÃ­sticas Principales

- **5 Modelos ML/DL:** Random Forest, XGBoost, MLP, LSTM-DNN, Stacking Ensemble
- **IngenierÃ­a de Features Avanzada (24+ variables):**
  - **Momentum:** Deltas (delta_1_2, evolution_3m), promedios y direcciÃ³n de tendencia
  - **Sensibilidad al Precio:** Cambios porcentuales, elasticidad precio-demanda, ingreso potencial
  - **Desviaciones:** Z-scores, diferencias vs promedio, coeficientes de volatilidad
  - **Rolling Windows:** 2 ventanas temporales parametrizables (mean + std)
  - **Clustering K-Means:** SegmentaciÃ³n automÃ¡tica de tiendas
  - **Balanceo SMOTE:** Opcional para clases desbalanceadas
- **API REST con FastAPI:** 5 endpoints documentados con Swagger UI
- **Frontend Streamlit:** Interfaz interactiva con explicabilidad SHAP
- **ValidaciÃ³n Temporal:** TimeSeriesSplit para prevenir data leakage
- **Sistema de Respaldo:** GestiÃ³n automÃ¡tica de datasets con KaggleHub

ğŸ“– **Detalles tÃ©cnicos:** Ver [docs/TECHNICAL_DETAILS.md](docs/TECHNICAL_DETAILS.md)  
ğŸ“– **DocumentaciÃ³n API:** Ver [docs/API.md](docs/API.md)

## Capturas de Pantalla

### Vista de PredicciÃ³n
![Vista de PredicciÃ³n](docs/screenshots/prediction-view.png)

### Panel de Monitoreo
![Panel de Monitoreo](docs/screenshots/monitoring-view.png)

## TecnologÃ­as Utilizadas

**Machine Learning:** scikit-learn, XGBoost, TensorFlow, imbalanced-learn, SHAP  
**Backend:** FastAPI, Pydantic, uvicorn  
**Frontend:** Streamlit, Plotly, httpx  
**Data:** pandas, numpy, KaggleHub  
**QA:** Black, Pylint, Mypy, Isort, pytest

ğŸ“– **Ver versiones completas:** [docs/INSTALLATION.md](docs/INSTALLATION.md)

## MÃ©tricas de los Modelos

Comparativa de rendimiento (dataset de validaciÃ³n con TimeSeriesSplit):

| Modelo            | RMSE  | MAE   | RÂ²        | Tipo              | Estado             |
| :---------------- | :---- | :---- | :-------- | :---------------- | :----------------- |
| **Random Forest** | 0.028 | 0.017 | **0.999** | Tree-based        | âœ… Ã“ptimo           |
| XGBoost           | 0.120 | 0.052 | 0.984     | Gradient Boosting | âœ… Excelente        |
| Stacking Ensemble | 0.821 | 0.807 | 0.276     | Ensemble          | âš ï¸ Bajo rendimiento |
| MLP               | 0.791 | 0.591 | 0.327     | Neural Network    | âš ï¸ Requiere ajuste  |
| LSTM-DNN          | 6.348 | 6.271 | -42.330   | Neural Network    | âŒ Fallo crÃ­tico    |

**Conclusiones:**
- **Random Forest es el modelo ganador** con RÂ²=0.999, superando incluso al Stacking Ensemble
- Los modelos tree-based (RF, XGBoost) superan significativamente a Deep Learning en datos tabulares pequeÃ±os
- **El Stacking Ensemble tiene rendimiento inferior** (RÂ²=0.276) a sus estimadores base, posiblemente por:
  - Overfitting del meta-estimador en validaciÃ³n temporal
  - Desbalance en los pesos de combinaciÃ³n
  - Incompatibilidad entre predicciones de estimadores heterogÃ©neos
- **LSTM-DNN fallÃ³ completamente** (RÂ²=-42.33) indicando divergencia en entrenamiento
- Deep Learning requiere datasets mÃ¡s grandes para convergencia Ã³ptima
- TimeSeriesSplit previene overfitting temporal y data leakage

**RecomendaciÃ³n:** Usar **Random Forest** como modelo de producciÃ³n por su estabilidad y rendimiento superior

## DocumentaciÃ³n Adicional

- ğŸ“˜ [GuÃ­a de InstalaciÃ³n](docs/INSTALLATION.md) - ConfiguraciÃ³n completa del entorno
- ğŸ”§ [Detalles TÃ©cnicos](docs/TECHNICAL_DETAILS.md) - MetodologÃ­a, arquitectura y features
- ğŸŒ [DocumentaciÃ³n API](docs/API.md) - Endpoints y ejemplos de uso
- ğŸ—ï¸ [Arquitectura Frontend](app/README.md) - Patrones SOLID y estructura modular

## Universidad AndrÃ©s Bello - 2025

**Asignatura:** ACIF104 - Aprendizaje de MÃ¡quinas  
**Docente:** OMAR IVÃN SALINAS SILVA  
**Periodo:** Sexto Trimestre 2025
